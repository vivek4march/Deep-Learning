{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from random import shuffle, seed\n",
    "import string\n",
    "# non-standard dependencies:\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "imgs = json.load(open('/home/vivek/data/COCO/image/dataset_coco.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'dataset'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cocoid': 391895,\n",
       " 'filename': 'COCO_val2014_000000391895.jpg',\n",
       " 'filepath': 'val2014',\n",
       " 'imgid': 0,\n",
       " 'sentences': [{'imgid': 0,\n",
       "   'raw': 'A man with a red helmet on a small moped on a dirt road. ',\n",
       "   'sentid': 770337,\n",
       "   'tokens': ['a',\n",
       "    'man',\n",
       "    'with',\n",
       "    'a',\n",
       "    'red',\n",
       "    'helmet',\n",
       "    'on',\n",
       "    'a',\n",
       "    'small',\n",
       "    'moped',\n",
       "    'on',\n",
       "    'a',\n",
       "    'dirt',\n",
       "    'road']},\n",
       "  {'imgid': 0,\n",
       "   'raw': 'Man riding a motor bike on a dirt road on the countryside.',\n",
       "   'sentid': 771687,\n",
       "   'tokens': ['man',\n",
       "    'riding',\n",
       "    'a',\n",
       "    'motor',\n",
       "    'bike',\n",
       "    'on',\n",
       "    'a',\n",
       "    'dirt',\n",
       "    'road',\n",
       "    'on',\n",
       "    'the',\n",
       "    'countryside']},\n",
       "  {'imgid': 0,\n",
       "   'raw': 'A man riding on the back of a motorcycle.',\n",
       "   'sentid': 772707,\n",
       "   'tokens': ['a',\n",
       "    'man',\n",
       "    'riding',\n",
       "    'on',\n",
       "    'the',\n",
       "    'back',\n",
       "    'of',\n",
       "    'a',\n",
       "    'motorcycle']},\n",
       "  {'imgid': 0,\n",
       "   'raw': 'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ',\n",
       "   'sentid': 776154,\n",
       "   'tokens': ['a',\n",
       "    'dirt',\n",
       "    'path',\n",
       "    'with',\n",
       "    'a',\n",
       "    'young',\n",
       "    'person',\n",
       "    'on',\n",
       "    'a',\n",
       "    'motor',\n",
       "    'bike',\n",
       "    'rests',\n",
       "    'to',\n",
       "    'the',\n",
       "    'foreground',\n",
       "    'of',\n",
       "    'a',\n",
       "    'verdant',\n",
       "    'area',\n",
       "    'with',\n",
       "    'a',\n",
       "    'bridge',\n",
       "    'and',\n",
       "    'a',\n",
       "    'background',\n",
       "    'of',\n",
       "    'cloud',\n",
       "    'wreathed',\n",
       "    'mountains']},\n",
       "  {'imgid': 0,\n",
       "   'raw': 'A man in a red shirt and a red hat is on a motorcycle on a hill side.',\n",
       "   'sentid': 781998,\n",
       "   'tokens': ['a',\n",
       "    'man',\n",
       "    'in',\n",
       "    'a',\n",
       "    'red',\n",
       "    'shirt',\n",
       "    'and',\n",
       "    'a',\n",
       "    'red',\n",
       "    'hat',\n",
       "    'is',\n",
       "    'on',\n",
       "    'a',\n",
       "    'motorcycle',\n",
       "    'on',\n",
       "    'a',\n",
       "    'hill',\n",
       "    'side']}],\n",
       " 'sentids': [770337, 771687, 772707, 776154, 781998],\n",
       " 'split': 'test'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123287"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = imgs['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1019785, 'a'),\n",
       " (224758, 'on'),\n",
       " (212689, 'of'),\n",
       " (206178, 'the'),\n",
       " (191793, 'in'),\n",
       " (161216, 'with'),\n",
       " (146755, 'and'),\n",
       " (102390, 'is'),\n",
       " (75957, 'man'),\n",
       " (71183, 'to'),\n",
       " (55190, 'sitting'),\n",
       " (51987, 'an'),\n",
       " (50467, 'two'),\n",
       " (44506, 'at'),\n",
       " (44297, 'standing'),\n",
       " (43707, 'people'),\n",
       " (42776, 'are'),\n",
       " (38867, 'next'),\n",
       " (37898, 'white'),\n",
       " (35372, 'woman')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_thr = 5\n",
    "# Count the number of words. : use dict.items(), dict.keys(), and dict.values() respectively.\n",
    "counts ={}\n",
    "\n",
    "for img in imgs:\n",
    "    for sent in img['sentences']:\n",
    "        for w in sent['tokens']:\n",
    "            counts[w] = counts.get(w, 0) + 1\n",
    "cw = sorted([(count,w) for w,count in counts.items()], reverse=True)\n",
    "cw[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_words = sum(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27929"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_words = [w for w, n in counts.items() if n <= count_thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wreathed'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18443"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wreathed',\n",
       " 'bakeware',\n",
       " 'inhales',\n",
       " 'goodness',\n",
       " 'coworker',\n",
       " 'dwellers',\n",
       " 'bmx',\n",
       " 'geoup',\n",
       " 'gouged',\n",
       " 'socket']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_count = sum(counts[w] for w in bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32382"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = [w for w, n in counts.items() if n > count_thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'man', 'with', 'red', 'helmet', 'on', 'small', 'moped', 'dirt', 'road']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9486"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad words: 18443/27929 = 66.04%\n"
     ]
    }
   ],
   "source": [
    "print('number of bad words: %d/%d = %.2f%%'  % (len(bad_words), len(counts), len(bad_words)*100.0/len(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of UNKs: 32382/6454115 = 0.50%\n"
     ]
    }
   ],
   "source": [
    "print('number of UNKs: %d/%d = %.2f%%' % (bad_count, total_words, bad_count*100.0/total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets look at the distribution of lengths as well\n",
    "\n",
    "sent_length ={}\n",
    "for img in imgs:\n",
    "    for sent in img['sentences']:\n",
    "        txt = sent['tokens']\n",
    "        nw = len(txt)\n",
    "        sent_length[nw] = sent_length.get(nw, 0) + 1\n",
    "        \n",
    "max_length = max(sent_length.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if bad_count > 0:\n",
    "    vocab.append('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    img['final_captions'] = []\n",
    "    for sent in img['sentences']:\n",
    "        txt = sent['tokens']\n",
    "        caption = [w if counts.get(w,0) > count_thr else 'UNK' for w in txt]\n",
    "        img['final_captions'].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27929"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123287"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'man', 'with', 'red', 'helmet', 'on', 'small', 'moped', 'dirt', 'road']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616767"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(img['final_captions']) for img in imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
